% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/auto_catboost_gpu.R
\name{auto_catboost_gpu}
\alias{auto_catboost_gpu}
\title{Automatic model tununig using Bayesian optimazation}
\usage{
auto_catboost_gpu(
  x,
  y,
  cat_features = NULL,
  iterations = list(lower = 500, upper = 1000),
  learning_rate = list(lower = 0.001, upper = 0.05),
  l2_leaf_reg = list(lower = 0, upper = 5),
  depth = list(lower = 1, upper = 10),
  bagging_temperature = list(lower = 0, upper = 100),
  border_count = list(lower = 1, upper = 254),
  verbose = "Silent",
  k = 6,
  bo_iters = 10,
  init_design = 20,
  validation_error_metric = "RMSE",
  ...
)
}
\arguments{
\item{x}{Indepandent variables (Features)}

\item{y}{Depandent variable}

\item{cat_features}{Name of the categorical variables}

\item{iterations}{The maximum number of trees that can be built when solving
machine learning problems.When using other parameters that limit the number
of iterations, the final number of trees may be less than the number
specified in this parameter. Default value: 1000}

\item{learning_rate}{The learning rate. Used for reducing the gradient step.
Default value: 0.03}

\item{l2_leaf_reg}{L2 regularization coefficient. Used for leaf value
calculation. Any positive values are allowed. Default value: 3}

\item{depth}{Depth of the tree. The value can be any integer up to 16.
It is recommended to use values in the range \code{[1; 10]}. Default value: 6}

\item{bagging_temperature}{Controls intensity of Bayesian bagging.
The higher the temperature the more aggressive bagging is.
Typical values are in the range \code{[0, 1]} (0 is for no bagging).
Possible values are in the range \code{0<= < +âˆž)}. Default value: 1}

\item{border_count}{Maximum number of borders used in target binarization
for categorical features that need it. If TargetBorderCount is
specified in 'simple_ctr', 'combinations_ctr' or 'per_feature_ctr' option
it overrides this value. Default value: 1}

\item{verbose}{Possible values: 'Silent', 'Verbose', 'Info', 'Debug'
Default value: 'Silent'}

\item{k}{An integer to specify the number of folds.}

\item{bo_iters}{Maximum iteration for Bayesian optimazation.Default value: 10}

\item{init_design}{Length of the initial design}

\item{validation_error_metric}{Later}

\item{\dots}{Other parameters passed to catboost.train's param argument.}
}
\description{
\Sexpr[results=rd, stage=render]{lifecycle::badge("experimental")}
Automatic model tununig using Bayesian optimazation
}
\examples{
\dontrun{
# A toy example

data(iris, package = "datasets")

fit <- auto_catboost_reg(
  iris,
  label_col_name = "Petal.Length",
  cat_features = "Species",
  has_time = FALSE,
  fold_count = 3,
  type = "Classical",
  partition_random_seed = 0,
  shuffle = TRUE,
  stratified = FALSE,
  early_stopping_rounds = NULL,
  iterations = list(lower = 100, upper = 110),
  learning_rate = list(lower = 0.001, upper = 0.05),
  l2_leaf_reg = list(lower = 0, upper = 5),
  depth = list(lower = 1, upper = 10),
  bagging_temperature = list(lower = 0, upper = 100),
  rsm = list(lower = 0, upper = 1),
  border_count = list(lower = 1, upper = 254),
  bo_iters = 2
)


varimp <- get_var_imp(fit$model)

plot_varimp(varimp)
}
}
\author{
Resul Akay
}
